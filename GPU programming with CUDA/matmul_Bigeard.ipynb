{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "matmul",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH8n8ipvlw5o",
        "colab_type": "code",
        "outputId": "8b9867a9-ce35-46bb-9988-e85c587be144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "! pip install git+git://github.com/frehseg/nvcc4jupyter.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/frehseg/nvcc4jupyter.git\n",
            "  Cloning git://github.com/frehseg/nvcc4jupyter.git to /tmp/pip-req-build-r7xnfk_e\n",
            "  Running command git clone -q git://github.com/frehseg/nvcc4jupyter.git /tmp/pip-req-build-r7xnfk_e\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.1 from git+git://github.com/frehseg/nvcc4jupyter.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.1-cp36-none-any.whl size=2095 sha256=b88320ba66674a21bc8669178806597ac893cae8fc32a9ed33d5c6587cdf82e1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z_fdg6pl/wheels/a4/a5/24/17a2b61f9a725a10155cc6fca753aae28436921df21fa16114\n",
            "Successfully built NVCCPlugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F59RI6imGKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX_Ws_yhnrYC",
        "colab_type": "text"
      },
      "source": [
        "### Version basique\n",
        "\n",
        "Version n'utilisant que la mémoire globale du GPU. Chaque bloc étant limité à 1024 threads, une tuile carrée a des dimensions maximales de 32x32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "dd987c93-5ae0-4eed-e3bd-e5b11d8bcfcc",
        "id": "R4mQsQyXKnQB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <time.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "#define TILE_WIDTH 16\n",
        "#define SIZE 20\n",
        "\n",
        "/********************** kernel **************************/\n",
        "__global__\n",
        "void matmul(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_LigneA, int nb_LigneB)\n",
        "{\n",
        "  int ligne = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (ligne < nb_LigneA && col < nb_LigneB) {\n",
        "      for(int i = 0; i < nb_ColA; i++){\n",
        "          C[ligne * nb_ColB + col] += A[ligne * nb_ColA + i] * B[i * nb_ColB + col];\n",
        "      }\n",
        "  }\n",
        "}\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  int dev = 0;\n",
        "  cudaDeviceProp deviceProp;\n",
        "  cudaGetDeviceProperties(&deviceProp, dev);\n",
        "  printf(\"device %d: %s \", dev, deviceProp.name);\n",
        "  cudaSetDevice(dev);\n",
        " \n",
        "  int n_iter = 10;\n",
        "  for(int j = 0; j < n_iter; j++){\n",
        "      \n",
        "  float *A, *B, *C, *gpu_A, *gpu_B, *gpu_C;\n",
        "  int nbLigneA, nbLigneB, nbColA, nbColB;\n",
        "\n",
        "  \n",
        "  nbLigneA = TILE_WIDTH * SIZE;\n",
        "  nbLigneB = TILE_WIDTH * SIZE;\n",
        "  nbColA = TILE_WIDTH * SIZE;\n",
        "  nbColB = TILE_WIDTH * SIZE;\n",
        "\n",
        "  A = (float*) malloc(nbLigneA * nbColA * sizeof(float));\n",
        "  B = (float*) malloc(nbLigneB * nbColB * sizeof(float));\n",
        "  C = (float*) malloc(nbLigneA * nbColB * sizeof(float));\n",
        "\n",
        "  /*Allocation de l'espace pour le GPU */\n",
        "  cudaMalloc((void**) &gpu_A, nbLigneA * nbColA * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_B, nbLigneB * nbColB * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_C, nbLigneA * nbColB * sizeof(float));\n",
        "\n",
        "  /* Initialisation de A et B*/\n",
        "  for (int i = 0; i < nbLigneA * nbColA; i++) {\n",
        "    A[i] = 1.0;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < nbLigneB * nbColB; i++) {\n",
        "    B[i] = 2.0;\n",
        "  }\n",
        "\n",
        "  /* Copie de A et B sur le GPU */\n",
        "  cudaMemcpy(gpu_A, A, nbLigneA * nbColA * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(gpu_B, B, nbLigneB * nbColB * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(gpu_C, C, nbLigneA * nbColB * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "  /* Lancement du kernel avec mesure du temps */\n",
        " dim3 threadsPerBlock (TILE_WIDTH, TILE_WIDTH);\n",
        " dim3 blocksPerGrid (nbLigneA / threadsPerBlock.y, nbLigneB / threadsPerBlock.x);\n",
        "\n",
        " clock_t start = clock();\n",
        "\n",
        " matmul<<<blocksPerGrid, threadsPerBlock>>>(gpu_A, gpu_B, gpu_C, nbColA, nbColB, nbLigneA, nbLigneB);\n",
        "\n",
        " clock_t end = clock();\n",
        " if(j == 0){\n",
        "\n",
        "  cudaMemcpy(C, gpu_C, nbLigneA * nbColB * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  /* Vérification du résultat*/\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < nbLigneA * nbColB; i++){\n",
        "      maxError = max(maxError, abs(C[i]- 2*nbLigneB));\n",
        "  }\n",
        "  printf(\"Max error: %f\\n\", maxError);\n",
        " }\n",
        "\n",
        " double time_taken = ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        " printf(\"\\n Kernel took %f seconds to execute\\n\\n\", time_taken);\n",
        "\n",
        "  /* Libération de la mémoire sur le GPU*/ \n",
        "  cudaFree(gpu_A);\n",
        "  cudaFree(gpu_B);\n",
        "  cudaFree(gpu_C);\n",
        "\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(C);\n",
        "}\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device 0: Tesla P4 Max error: 0.000000\n",
            "\n",
            " Kernel took 0.000017 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.000013 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.000012 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.000011 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.000011 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.000011 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.000011 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.000011 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.000011 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.000011 seconds to execute\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_d7NNW94FaS",
        "colab_type": "text"
      },
      "source": [
        "#### Pour la version basique, le temps d'execution du kernel semble se stabiliser entre 1e-5 et 2.5e-5 sec. Using TILE_WIDTH of 32 or 16 doesn't impact the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-eFewsdOfTW",
        "colab_type": "text"
      },
      "source": [
        "#### Regardons maintenant l'influence de l'utilisation d'un GPU en comparant le resultat avec la version CPU:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuW-5p-GLc5P",
        "colab_type": "code",
        "outputId": "f74b50f6-b158-42b2-955f-49dbf260d251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <time.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "#define TILE_WIDTH 16\n",
        "#define SIZE 20\n",
        "\n",
        "/********************** kernel **************************/\n",
        "void matmul(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_LigneA, int nb_LigneB)\n",
        "{\n",
        "  for (int i = 0; i < nb_LigneA; i++) {\n",
        "        for (int j = 0; j < nb_ColB; j++) {\n",
        "            int sum = 0;\n",
        "            for (int k = 0; k < nb_ColA; k++)\n",
        "                sum = sum + A[i * nb_ColA + k] * B[k * nb_ColB + j];\n",
        "            C[i * nb_ColB + j] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  int dev = 0;\n",
        "  cudaDeviceProp deviceProp;\n",
        "  cudaGetDeviceProperties(&deviceProp, dev);\n",
        "  printf(\"device %d: %s \", dev, deviceProp.name);\n",
        "  cudaSetDevice(dev);\n",
        "\n",
        "  int n_iter = 10;\n",
        "  for(int j = 0; j < n_iter; j++){\n",
        "      \n",
        "  float *A, *B, *C;\n",
        "  int nbLigneA, nbLigneB, nbColA, nbColB;\n",
        "\n",
        "  nbLigneA = TILE_WIDTH * SIZE;\n",
        "  nbLigneB = TILE_WIDTH * SIZE;\n",
        "  nbColA = TILE_WIDTH * SIZE;\n",
        "  nbColB = TILE_WIDTH * SIZE;\n",
        "\n",
        "  A = (float*) malloc(nbLigneA * nbColA * sizeof(float));\n",
        "  B = (float*) malloc(nbLigneB * nbColB * sizeof(float));\n",
        "  C = (float*) malloc(nbLigneA * nbColB * sizeof(float));\n",
        "\n",
        "  /* Initialisation de A et B*/\n",
        "  for (int i = 0; i < nbLigneA * nbColA; i++) {\n",
        "    A[i] = 1.0;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < nbLigneB * nbColB; i++) {\n",
        "    B[i] = 2.0;\n",
        "  }\n",
        "\n",
        "  /* Lancement du kernel avec mesure du temps */\n",
        "\n",
        " clock_t start = clock();\n",
        "\n",
        " matmul(A, B, C, nbColA, nbColB, nbLigneA, nbLigneB);\n",
        "\n",
        " clock_t end = clock();\n",
        "\n",
        " if(j == 0){\n",
        "\n",
        "  /* Vérification du résultat*/\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < nbLigneA * nbColB; i++){\n",
        "      maxError = max(maxError, abs(C[i]- 2*nbLigneB));\n",
        "  }\n",
        "  printf(\"Max error: %f\\n\", maxError);\n",
        " }\n",
        "\n",
        " double time_taken = ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        " printf(\"\\n Kernel took %f seconds to execute\\n\\n\", time_taken);\n",
        "\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(C);\n",
        "}\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device 0: Tesla P4 Max error: 0.000000\n",
            "\n",
            " Kernel took 0.261367 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.258055 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.208877 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.209259 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.210120 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.209867 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.214595 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.222661 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.208501 seconds to execute\n",
            "\n",
            "\n",
            " Kernel took 0.210239 seconds to execute\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ILssxqId6tL",
        "colab_type": "text"
      },
      "source": [
        "#### La version CPU mets entre 1.7 et 1.9 sec pour s'executer avec un TILE_WIDTH de 32. Alors qu'avec un TILE_WIDTH de 16, le programme met entre 0.2 et 0.26 sec."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHqbdT9JAOgD",
        "colab_type": "text"
      },
      "source": [
        "### Version tuilée:\n",
        "\n",
        "Les algorithmes de produit de matrices les plus performants décomposent les algorithmes en tuile. \n",
        "\n",
        "- Chaque thread de chaque bloc calcule un élément la matrice C.\n",
        "- Dans chaque bloc, une tuile de la matrice A et une tuile de la matrice B sont stockées en mémoire partagée (dans des vecteurs 2 dimensions [TILE_WIDTH][TILE_WIDTH], stockés sous la forme de tableaux uni-dimensionnels row-major).\n",
        "-  Chaque thread copie l'élément des matrices A et B correspondant à ses coordonnées en mémoire partagée, attend que les données sont disponibles puis effectue le calcul et le stocke dans une variable temporaire.\n",
        "- Tant que le calcul n'est pas fini, le thread met à jour cette même variable temporaire.\n",
        "- La valeur temporaire est recopiée en mémoire globale dans la matrice C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI2fGoIeRzUW",
        "colab_type": "text"
      },
      "source": [
        "#### Comparaison de la version CPU, basique et de la version tuilee:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHmFVVOF4Bch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "054e5525-b226-42a3-992a-b7a42d60fcd6"
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <time.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "#define TILE_WIDTH 16\n",
        "#define SIZE 20\n",
        "\n",
        "\n",
        "/* CPU Version */\n",
        "void matmul(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_LigneA, int nb_LigneB)\n",
        "{\n",
        "  for (int i = 0; i < nb_LigneA; i++) {\n",
        "        for (int j = 0; j < nb_ColB; j++) {\n",
        "            int sum = 0;\n",
        "            for (int k = 0; k < nb_ColA; k++)\n",
        "                sum = sum + A[i * nb_ColA + k] * B[k * nb_ColB + j];\n",
        "            C[i * nb_ColB + j] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Version Basic */\n",
        "__global__\n",
        "void basicmatmul(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_LigneA, int nb_LigneB)\n",
        "{\n",
        "  int ligne = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (ligne < nb_LigneA && col < nb_LigneB) {\n",
        "      for(int i = 0; i < nb_ColA; i++){\n",
        "          C[ligne * nb_ColB + col] += A[ligne * nb_ColA + i] * B[i * nb_ColB + col];\n",
        "      }\n",
        "  }\n",
        "}\n",
        "\n",
        "/* Version Tuilee */\n",
        "__global__\n",
        "void tuileematmul(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_LigneA, int nb_LigneB)\n",
        "{\n",
        "    int blockRow = blockIdx.y;\n",
        "    int blockCol = blockIdx.x;\n",
        "    float* Csub = &C[nb_ColB * TILE_WIDTH * blockRow + TILE_WIDTH * blockCol];\n",
        "    float Cvalue = 0;\n",
        "    int row = threadIdx.y;\n",
        "    int col = threadIdx.x;\n",
        "    for (int m = 0; m < (nb_ColA / TILE_WIDTH); ++m) {\n",
        "        float* Asub = &A[nb_ColA * TILE_WIDTH * blockRow + TILE_WIDTH * m];\n",
        "        float* Bsub = &B[nb_ColB * TILE_WIDTH * m + TILE_WIDTH * blockCol];\n",
        "        __shared__ float As[TILE_WIDTH][TILE_WIDTH];\n",
        "        __shared__ float Bs[TILE_WIDTH][TILE_WIDTH];\n",
        "        As[row][col] = Asub[row * nb_ColA + col];\n",
        "        Bs[row][col] = Bsub[row * nb_ColB + col];\n",
        "        __syncthreads();\n",
        "        for (int e = 0; e < TILE_WIDTH; ++e)\n",
        "            Cvalue += As[row][e] * Bs[e][col];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    Csub[row * nb_ColA + col] = Cvalue;\n",
        "}\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  int dev = 0;\n",
        "  cudaDeviceProp deviceProp;\n",
        "  cudaGetDeviceProperties(&deviceProp, dev);\n",
        "  printf(\"device %d: %s \", dev, deviceProp.name);\n",
        "  cudaSetDevice(dev);\n",
        "\n",
        "  float *A, *B, *C, *gpu_A, *gpu_B, *gpu_C;\n",
        "  int nbRowA, nbRowB, nbColA, nbColB;\n",
        "\n",
        "  \n",
        "  nbRowA = TILE_WIDTH * SIZE;\n",
        "  nbRowB = TILE_WIDTH * SIZE;\n",
        "  nbColA = TILE_WIDTH * SIZE;\n",
        "  nbColB = TILE_WIDTH * SIZE;\n",
        "\n",
        "  A = (float*) malloc(nbRowA * nbColA * sizeof(float));\n",
        "  B = (float*) malloc(nbRowB * nbColB * sizeof(float));\n",
        "  C = (float*) malloc(nbRowA * nbColB * sizeof(float));\n",
        "\n",
        "  /* GPU space allocation */\n",
        "  cudaMalloc((void**) &gpu_A, nbRowA * nbColA * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_B, nbRowB * nbColB * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_C, nbRowA * nbColB * sizeof(float));\n",
        "\n",
        "  /* A & B initialization */\n",
        "  for (int i = 0; i < nbRowA * nbColA; i++) {\n",
        "    A[i] = 1.0;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < nbRowB * nbColB; i++) {\n",
        "    B[i] = 2.0;\n",
        "  }\n",
        "\n",
        "  /* Copy of A & B on GPU */\n",
        "  cudaMemcpy(gpu_A, A, nbRowA * nbColA * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(gpu_B, B, nbRowB * nbColB * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(gpu_C, C, nbRowA * nbColB * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        " dim3 threadsPerBlock (TILE_WIDTH, TILE_WIDTH);\n",
        " dim3 blocksPerGrid (nbRowA / threadsPerBlock.y, nbRowB / threadsPerBlock.x);\n",
        "\n",
        " double cpu_time = 0.0;\n",
        " float cpu_max_error = 0.0f;\n",
        " double basic_time = 0.0;\n",
        " float basic_max_error = 0.0f;\n",
        " double shared_mem_time = 0.0;\n",
        " float shared_mem_max_error = 0.0f;\n",
        "\n",
        " int n_iter = 20;\n",
        " for(int i = 0; i < n_iter; i++){\n",
        "     \n",
        " /* CPU */\n",
        " clock_t start = clock();\n",
        " matmul(A, B, C, nbColA, nbColB, nbRowA, nbRowB);\n",
        " clock_t end = clock();\n",
        " cpu_time += ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        " if(i == 0){\n",
        "    /* Vérification du résultat*/\n",
        "    for (int i = 0; i < nbRowA * nbColB; i++){\n",
        "        cpu_max_error = max(cpu_max_error, abs(C[i]- 2*nbRowB));\n",
        "    }\n",
        "  }\n",
        "\n",
        " /* Basic Version */\n",
        " start = clock();\n",
        " basicmatmul<<<blocksPerGrid, threadsPerBlock>>>(gpu_A, gpu_B, gpu_C, nbColA, nbColB, nbRowA, nbRowB);\n",
        " end = clock();\n",
        " basic_time += ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        " if(i == 0){\n",
        "    cudaMemcpy(C, gpu_C, nbRowA * nbColB * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    /* Vérification du résultat*/\n",
        "    for (int i = 0; i < nbRowA * nbColB; i++){\n",
        "        basic_max_error = max(basic_max_error, abs(C[i]- 2*nbRowB));\n",
        "    }\n",
        "  }\n",
        "\n",
        " /* Shared Memory Version */\n",
        " start = clock();\n",
        " tuileematmul<<<blocksPerGrid, threadsPerBlock>>>(gpu_A, gpu_B, gpu_C, nbColA, nbColB, nbRowA, nbRowB);\n",
        " end = clock();\n",
        " shared_mem_time += ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        " if(i == 0){\n",
        "    cudaMemcpy(C, gpu_C, nbRowA * nbColB * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    /* Vérification du résultat*/\n",
        "    for (int i = 0; i < nbRowA * nbColB; i++){\n",
        "        shared_mem_max_error = max(shared_mem_max_error, abs(C[i]- 2*nbRowB));\n",
        "    }\n",
        "  }\n",
        " }\n",
        " \n",
        " printf(\"\\nCPU version took %f seconds to execute \\n\", cpu_time/n_iter);\n",
        " printf(\"Max error: %f\\n\", cpu_max_error);\n",
        " \n",
        " printf(\"\\nBasic version took %f seconds to execute \\n\", basic_time/n_iter);\n",
        " printf(\"Max error: %f\\n\", basic_max_error);\n",
        "\n",
        " printf(\"\\nShared memory version took %f seconds to execute \\n\", shared_mem_time/n_iter);\n",
        " printf(\"Max error: %f\\n\", shared_mem_max_error);\n",
        "\n",
        "  /* Libération de la mémoire sur le GPU*/ \n",
        "  cudaFree(gpu_A);\n",
        "  cudaFree(gpu_B);\n",
        "  cudaFree(gpu_C);\n",
        "\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(C);\n",
        "}"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device 0: Tesla P4 \n",
            "CPU version took 0.212490 seconds to execute \n",
            "Max error: 0.000000\n",
            "\n",
            "Basic version took 0.000028 seconds to execute \n",
            "Max error: 0.000000\n",
            "\n",
            "Shared memory version took 0.000006 seconds to execute \n",
            "Max error: 0.000000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOjISO3g-fiL",
        "colab_type": "text"
      },
      "source": [
        "#### CuBLAS version\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwEjLtOJrAUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a33bb5b0-8192-43cf-f7e3-c1a25b16ae3e"
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <time.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "#define TILE_WIDTH 32\n",
        "#define SIZE 20\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  int dev = 0;\n",
        "  cudaDeviceProp deviceProp;\n",
        "  cudaGetDeviceProperties(&deviceProp, dev);\n",
        "  printf(\"device %d: %s \", dev, deviceProp.name);\n",
        "  cudaSetDevice(dev);\n",
        " \n",
        "  float *A, *B, *C, *gpu_A, *gpu_B, *gpu_C;\n",
        "  int nbRowA, nbRowB, nbColA, nbColB;\n",
        "\n",
        "  \n",
        "  nbRowA = TILE_WIDTH * SIZE;\n",
        "  nbRowB = TILE_WIDTH * SIZE;\n",
        "  nbColA = TILE_WIDTH * SIZE;\n",
        "  nbColB = TILE_WIDTH * SIZE;\n",
        "\n",
        "  A = (float*) malloc(nbRowA * nbColA * sizeof(float));\n",
        "  B = (float*) malloc(nbRowB * nbColB * sizeof(float));\n",
        "  C = (float*) malloc(nbRowA * nbColB * sizeof(float));\n",
        "\n",
        "  /* GPU space allocation */\n",
        "  cudaMalloc((void**) &gpu_A, nbRowA * nbColA * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_B, nbRowB * nbColB * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_C, nbRowA * nbColB * sizeof(float));\n",
        "\n",
        "  /* A & B initialization */\n",
        "  for (int i = 0; i < nbRowA * nbColA; i++) {\n",
        "    A[i] = 1.0;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < nbRowB * nbColB; i++) {\n",
        "    B[i] = 2.0;\n",
        "  }\n",
        "\n",
        "  /* Copy of A & B on GPU */\n",
        "  cudaMemcpy(gpu_A, A, nbRowA * nbColA * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(gpu_B, B, nbRowB * nbColB * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(gpu_C, C, nbRowA * nbColB * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        " dim3 threadsPerBlock (TILE_WIDTH, TILE_WIDTH);\n",
        " dim3 blocksPerGrid (nbRowA / threadsPerBlock.y, nbRowB / threadsPerBlock.x);\n",
        "\n",
        " double cuBLAS_time = 0.0;\n",
        " float cuBLAS_max_error = 0.0f;\n",
        "\n",
        "int n_iter = 20;\n",
        " for(int i = 0; i < n_iter; i++){\n",
        "\n",
        "\n",
        " /* cuBLAS Version */\n",
        " const float alf = 1;\n",
        " const float bet = 0;\n",
        " const float *alpha = &alf;\n",
        " const float *beta = &bet;\n",
        " \n",
        " cublasHandle_t handle;\n",
        " cublasCreate(&handle);\n",
        " \n",
        " /* Warming up */\n",
        " cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, nbRowA, nbColB, nbColA, alpha, gpu_A, nbRowA, gpu_B, nbColA, beta, gpu_C, nbRowA);\n",
        "\n",
        " clock_t start = clock();\n",
        " cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, nbRowA, nbColB, nbColA, alpha, gpu_A, nbRowA, gpu_B, nbColA, beta, gpu_C, nbRowA);\n",
        " clock_t end = clock();\n",
        "\n",
        " // Destroy the handle\n",
        " cublasDestroy(handle);\n",
        "\n",
        " cuBLAS_time += ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        " if(i == 0){\n",
        "    cudaMemcpy(C, gpu_C, nbRowA * nbColB * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    /* Vérification du résultat*/\n",
        "    for (int i = 0; i < nbRowA * nbColB; i++){\n",
        "        cuBLAS_max_error = max(cuBLAS_max_error, abs(C[i]- 2*nbRowB));\n",
        "    }\n",
        "  }\n",
        " }\n",
        " printf(\"\\ncuBLAS version took %f seconds to execute \\n\", cuBLAS_time/n_iter);\n",
        " printf(\"Max error: %f\\n\", cuBLAS_max_error);\n",
        "\n",
        "  /* Libération de la mémoire sur le GPU*/ \n",
        "  cudaFree(gpu_A);\n",
        "  cudaFree(gpu_B);\n",
        "  cudaFree(gpu_C);\n",
        "\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(C);\n",
        " \n",
        "}\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device 0: Tesla P4 \n",
            "cuBLAS version took 0.000008 seconds to execute \n",
            "Max error: 0.000000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}