{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reduction",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xai9rG1XOK94",
        "colab_type": "code",
        "outputId": "4434c4be-7077-4d18-fc7d-fc2a99def7b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "! pip install git+git://github.com/frehseg/nvcc4jupyter.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/frehseg/nvcc4jupyter.git\n",
            "  Cloning git://github.com/frehseg/nvcc4jupyter.git to /tmp/pip-req-build-_ghd6ecr\n",
            "  Running command git clone -q git://github.com/frehseg/nvcc4jupyter.git /tmp/pip-req-build-_ghd6ecr\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.1-cp36-none-any.whl size=2095 sha256=e895917d61d9ee133a53c18ff56201de5ee4bd1f1e2cd6de066252e5985bee66\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9wzdbfvq/wheels/a4/a5/24/17a2b61f9a725a10155cc6fca753aae28436921df21fa16114\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht9vzx-ROM4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IkiPOPjBLL9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFmb-1EOX4jW",
        "colab_type": "code",
        "outputId": "044814d4-0f66-4a31-bd51-d81ce425ea37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "%%cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#define DIM 1024\n",
        "\n",
        "\n",
        "// Recursive Implementation \n",
        "int recursiveReduce(int *data, int const size)\n",
        "{\n",
        "    if (size == 1) return data[0];\n",
        "\n",
        "    int const stride = size / 2;\n",
        "\n",
        "    for (int i = 0; i < stride; i++)\n",
        "        data[i] += data[i + stride];\n",
        "\n",
        "    return recursiveReduce(data, stride);\n",
        "}\n",
        "\n",
        "__global__ void reduce1(int *g_idata, int *g_odata,\n",
        "                                     unsigned int  n)\n",
        "{\n",
        "    extern __shared__ int smem[];\n",
        "\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // boundary check\n",
        "    if (idx >= n) return;\n",
        "\n",
        "    smem[tid] = g_idata[idx];\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = 1; stride < blockDim.x; stride *= 2)\n",
        "    {\n",
        "        if ((tid % (2 * stride)) == 0)\n",
        "        {\n",
        "            smem[tid] += smem[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = smem[0];\n",
        "}\n",
        "\n",
        "__global__ void reduce2(int *g_idata, int *g_odata,\n",
        "                                     unsigned int  n)\n",
        "{\n",
        "    extern __shared__ int smem[];\n",
        "\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // boundary check\n",
        "    if (idx >= n) return;\n",
        "\n",
        "    smem[tid] = g_idata[idx];\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = 1; stride < blockDim.x; stride *= 2)\n",
        "    {\n",
        "        int index = 2 * stride * tid;\n",
        "     \n",
        "        if (index < blockDim.x)\n",
        "        {\n",
        "            smem[index] += smem[index + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = smem[0];\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void reduce3(int *g_idata, int *g_odata,\n",
        "                                     unsigned int  n)\n",
        "{\n",
        "    extern __shared__ int smem[];\n",
        "\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // boundary check\n",
        "    if (idx >= n) return;\n",
        "\n",
        "    smem[tid] = g_idata[idx];\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride =blockDim.x/2; stride>0; stride>>=1)\n",
        "    {     \n",
        "        if (tid < stride)\n",
        "        {\n",
        "            smem[tid] += smem[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = smem[0];\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void reduce_unroll(int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    extern __shared__ int smem[];\n",
        "\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "\n",
        "    // boundary check\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx >= n) return;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // set to smem by each threads\n",
        "    smem[tid] = idata[tid];\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in shared memory\n",
        "    if (blockDim.x >= 1024 && tid < 512) smem[tid] += smem[tid + 512];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (blockDim.x >= 512 && tid < 256) smem[tid] += smem[tid + 256];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (blockDim.x >= 256 && tid < 128) smem[tid] += smem[tid + 128];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (blockDim.x >= 128 && tid < 64)  smem[tid] += smem[tid + 64];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // unrolling warp\n",
        "    if (tid < 32)\n",
        "    {\n",
        "        volatile int *vsmem = smem;\n",
        "        vsmem[tid] += vsmem[tid + 32];\n",
        "        vsmem[tid] += vsmem[tid + 16];\n",
        "        vsmem[tid] += vsmem[tid +  8];\n",
        "        vsmem[tid] += vsmem[tid +  4];\n",
        "        vsmem[tid] += vsmem[tid +  2];\n",
        "        vsmem[tid] += vsmem[tid +  1];\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = smem[0];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, dev);\n",
        "    printf(\"device %d: %s \", dev, deviceProp.name);\n",
        "    cudaSetDevice(dev);\n",
        "    \n",
        "    int power = 10000;\n",
        "\n",
        "    int blocksize = DIM;   \n",
        "\n",
        "    /* Number of elements to reduce */\n",
        "    int size = 2 << power; \n",
        "    printf(\"With array size %d  :\", size);\n",
        "\n",
        "    dim3 block (blocksize, 1);\n",
        "    dim3 grid  ((size + block.x - 1) / block.x, 1);\n",
        "    printf(\"grid %d block %d\\n\", grid.x, block.x);\n",
        " \n",
        "    double cpu_time = 0.0;\n",
        "    double red1_time = 0.0;\n",
        "    double red2_time = 0.0;\n",
        "    double red3_time = 0.0;\n",
        "    double red_unroll_time = 0.0;\n",
        "\n",
        "    /* Allocate host memory */\n",
        "    size_t bytes = size * sizeof(int);\n",
        "    int *h_idata = (int *) malloc(bytes);\n",
        "    int *h_odata = (int *) malloc(grid.x * sizeof(int));\n",
        "    int *tmp     = (int *) malloc(bytes);\n",
        "\n",
        "    /* Initialize the array */\n",
        "    for (int i = 0; i < size; i++)\n",
        "        h_idata[i] = (int)( rand() & 0xFF );\n",
        "\n",
        "    memcpy (tmp, h_idata, bytes);\n",
        "\n",
        "    int gpu_sum = 0;\n",
        "\n",
        "    /* Allocate device memory */\n",
        "    int *d_idata = NULL;\n",
        "    int *d_odata = NULL;\n",
        "    cudaMalloc((void **) &d_idata, bytes);\n",
        "    cudaMalloc((void **) &d_odata, grid.x * sizeof(int));\n",
        " \n",
        "    int n_iter = 10;\n",
        "    for(int i = 0; i < n_iter; i++){\n",
        "\n",
        "    /* Cpu reduction */\n",
        "    clock_t start = clock();\n",
        "    int cpu_sum = recursiveReduce (tmp, size);\n",
        "    clock_t end = clock();\n",
        "    cpu_time += ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        "    if(i == 0){\n",
        "    printf(\"cpu reduce: %d\\n\", cpu_sum);\n",
        "    }\n",
        "\n",
        "    /* reduce1 */\n",
        "    cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice);\n",
        "    start = clock();\n",
        "    reduce1<<<grid.x, block, blocksize*sizeof(int)>>>(d_idata, d_odata,\n",
        "            size);\n",
        "    end = clock();\n",
        "    cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost);\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n",
        "    red1_time += ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        "    if(i == 0){\n",
        "    printf(\"reduce1: %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x,\n",
        "           block.x);\n",
        "    }\n",
        " \n",
        "     /* reduce2 */\n",
        "    cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice);\n",
        "    start = clock();\n",
        "    reduce2<<<grid.x, block, blocksize*sizeof(int)>>>(d_idata, d_odata,\n",
        "            size);\n",
        "    end = clock();\n",
        "    cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost);\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n",
        "    red2_time += ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        "    if(i == 0){\n",
        "    printf(\"reduce2: %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x,\n",
        "           block.x);\n",
        "    }\n",
        "\n",
        "    /* reduce3 */\n",
        "    cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice);\n",
        "    start = clock();\n",
        "    reduce3<<<grid.x, block, blocksize*sizeof(int)>>>(d_idata, d_odata,\n",
        "            size);\n",
        "    end = clock();\n",
        "    cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost);\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n",
        " \n",
        "    red3_time += ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        "    if(i == 0){\n",
        "    printf(\"reduce3: %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x,\n",
        "           block.x);\n",
        "    }\n",
        "\n",
        "    /* reduce_unroll */\n",
        "    cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice);\n",
        "    start = clock();\n",
        "    reduce_unroll<<<grid.x, block, blocksize*sizeof(int)>>>(d_idata, d_odata,\n",
        "            size);\n",
        "    end = clock();\n",
        "    cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost);\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n",
        " \n",
        "    red_unroll_time += ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        "    if(i == 0){\n",
        "    printf(\"reduce_unroll: %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x,\n",
        "           block.x);\n",
        "    }\n",
        "    }\n",
        "    printf(\"\\nRecursive version kernel took %f seconds to execute \\n\", cpu_time/n_iter);\n",
        "    printf(\"\\nInterleaved addressing with divergent branching took %f seconds to execute \\n\", red1_time/n_iter);\n",
        "    printf(\"\\nInterleaved addressing with bank conflicts took %f seconds to execute \\n\", red2_time/n_iter);\n",
        "    printf(\"\\nSequential addressing took %f seconds to execute \\n\", red3_time/n_iter);\n",
        "    printf(\"\\nUnroll version took %f seconds to execute \\n\", red_unroll_time/n_iter);\n",
        "\n",
        "    // free host memory\n",
        "    free(h_idata);\n",
        "    free(h_odata);\n",
        "\n",
        "    // free device memory\n",
        "    cudaFree(d_idata);\n",
        "    cudaFree(d_odata);\n",
        "\n",
        "    // reset device\n",
        "    cudaDeviceReset();\n",
        "\n",
        "    return EXIT_SUCCESS;\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device 0: Tesla T4 With array size 131072  :grid 128 block 1024\n",
            "cpu reduce: 16747465\n",
            "reduce1: 16747465 <<<grid 128 block 1024>>>\n",
            "reduce2: 16747465 <<<grid 128 block 1024>>>\n",
            "reduce3: 16747465 <<<grid 128 block 1024>>>\n",
            "reduce_unroll: 16747465 <<<grid 128 block 1024>>>\n",
            "\n",
            "Recursive version kernel took 0.000443 seconds to execute \n",
            "\n",
            "Interleaved addressing with divergent branching took 0.000008 seconds to execute \n",
            "\n",
            "Interleaved addressing with bank conflicts took 0.000005 seconds to execute \n",
            "\n",
            "Sequential addressing took 0.000005 seconds to execute \n",
            "\n",
            "Unroll version took 0.000005 seconds to execute \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA1TL403UnGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "67f858a9-cf3a-4903-8556-5fea5561e1d3"
      },
      "source": [
        "%%cu\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <time.h>\n",
        "\n",
        "\n",
        "int main(void) {\n",
        "  printf(\" Thrust Library version \\n\");\n",
        "\n",
        "  thrust::device_vector<int> D(131072, 1);\n",
        "  int sum_t;\n",
        " \n",
        "  for (int s = 1; s < 10; s++) {\n",
        "    clock_t start_gpu = clock();\n",
        "    sum_t = thrust::reduce(D.begin(), D.end());\n",
        "    clock_t end_gpu = clock();\n",
        "    int time_thrust = end_gpu - start_gpu;\n",
        "    printf(\"  t = %d µs \\n\", time_thrust);\n",
        "  }\n",
        "\n",
        "  printf(\"\\n   S = %d \", sum_t);\n",
        "\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Thrust Library version \n",
            "  t = 80 µs \n",
            "  t = 44 µs \n",
            "  t = 39 µs \n",
            "  t = 37 µs \n",
            "  t = 38 µs \n",
            "  t = 38 µs \n",
            "  t = 37 µs \n",
            "  t = 37 µs \n",
            "  t = 37 µs \n",
            "\n",
            "   S = 131072 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}